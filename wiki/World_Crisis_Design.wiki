#summary Implementation and Design for world crises tracker

=Introduction=

---------------------IMPORTANT NOTES---------------------<br />
We have confirmed that our import/export XML facility works on the app engine web site (with the same code that we turned in).  Initially, our program worked only on localhost, but not on the app engine web site. As you can imagine, this was very bizarre behavior and took a while to debug.  The solution was to manually go into the data viewer in the appengine data store and delete all previous malformed XML stored in the database.

Furthermore, our group was using the example on the project description website as a guide when we were creating our schema. We decided to use nested tags similar to the example shown on the website, something we noticed other groups did not use very much. We learned (eventually) that trying to parse nested XML tags is MUCH more complicated than parsing several single tags and as a result spent a great deal of time on this part of the project. We hope that this will be taken into consideration.<br />
---------------------IMPORTANT NOTES---------------------<br />

Link: http://world-crisis.appspot.com/

By the end of this project, weâ€™ll have a Google App Engine application that tracks world crises, similar to how IMdB tracks movies and movie stars.

IMDB has two major kinds of pages: movies/shows and people. Movies/shows link to people and people link back to movies/shows.

WC will have three major kinds of pages: crises, organizations, and people, and gain each will link to the others.

For the first phase of this project, we were required to:
    * collect data on four crises and post to Blackboard on the World Crises forum
    * create an XML schema and XML instance that validate, no agreement between groups about this in this phase
    * create a set of GAE datastore models to represent the data
    * create an import/export facility from the XML into GAE and back
    * import/export data on only the four crises of the group

=Collect data on four crises=
We collected data for the following 4 crises:
  * Haiti Earthquake
  * Indonesia (Sumatra) Earthquake
  * AIDS Pandemic
  * War in Darfur

Our data, as posted on Blackboard, was collected based on Professor Downing's minimum requirements:
    * crises
          ** name
          ** kind
          ** location
          ** date and time
          ** description
          ** human impact
          ** economic impact
          ** resources needed
          ** ways to help
          ** images (e.g. Flickr, etc.)
          ** videos (e.g. YouTube, etc.)
          ** social networks (e.g. Facebook, Twitter, etc.)
          ** links to other sites
          ** organizations
          ** people
    * organizations
          ** name
          ** kind
          ** location
          ** history
          ** contact info
          ** social networks (e.g. Facebook, Twitter, etc.)
          ** crises
          ** peopleCreate a set of GAE datastore models
    * people
          ** name
          ** kind
          ** location
          ** social networks (e.g. Facebook, Twitter, etc.)
          ** crises
          ** organizations

=Create an XML schema and XML instance=
Our Schema was roughly designed around Downing's specifications. There were some changes based on protected words, usually name or type. We used most things in sequence, so form is required. And we made many fields optional (0 or 1 instances). For most instances of multiplicity, instead of making multiple fields directly available, we created a single instance that allowed multiple elements inside.

One large difference between our design and the specifications is that we removed Ways to Help in favor of merging that data with resources needed.

We also made a single Impact type that would account for both Human and Economic impacts, as well as any other type of impact, such as Environmental.
Additionally, we added an optional gross cost under the overall Impacts Type (which is multiple impacts, plus the gross) which would allow information such as "Total humans affected" in neat understandable location.

In order to relate Crises and People and Organizations to each other, we used a system of keys and keyrefs, where the my_name field of each individual object is set up as a key in the xsd, so there are no replicated names. And each object has a related section that also have their own my_name's in them. Those my_name's are used as key references that require that their value matches some key. This guarantees that there are no hanging links.

=Create a set of GAE datastore models=
We used Beautiful Soup to parse the XML. We had three large outer tags (crises, people, organizations). We walk through the XML and store everything into a dictionary. Then we move everything from the dictionary into our internal datastore. For our data store design, we decided to make multiple tables and reference some tables by using the name property as a foreign key. We have a datastore table for all of the important tables (crises, related people, related organizations, locations, impacts, videos, images, resources needed, and social networks).

=Create an import/export facility=
== Upload ==
The GUI asks the user to select a .xml file to upload.  If no file or a file with a different extension is selected, the GUI will alert the user when the upload button is pressed.  The program will not upload the selected file until it matches a .xml extension.
== Download ==
When the user presses the download button, they are led to a page that displays the raw XML data for the 4 crises.  The user can do "File > Save As" to save it as a .xml file.


=External Module: Beautiful Soup=
  * Beautiful Soup- http://www.crummy.com/software/BeautifulSoup/
  * Download- http://www.crummy.com/software/BeautifulSoup/download/2.x/BeautifulSoup.2.1.1.py
Beautiful Soup is a Python HTML/XML parser designed for quick turnaround projects like screen-scraping. We use it in WC1.py to facilitate the import/export of XML data.  For convenience, the BeautifulSoup.py is included in the turnin zip file.